# ğŸ§  Evatt Mini Casebase

**Evatt Mini Casebase** is an AI-powered semantic legal case search system built with **FastAPI**, **Next.js**, **Qdrant**, and **Sentence Transformers**.  
It allows users to upload legal case files (PDF or TXT), converts them into machine-understandable embeddings, stores them in a vector database, and enables natural language search over those documents.

---

## ğŸš€ Overview

This application demonstrates how artificial intelligence can be used to make legal document search **semantic** instead of **keyword-based**.

Users can:

- Upload legal case summaries or judgments in `.txt` or `.pdf` format.
- Automatically convert the document text into embeddings (AI numeric representations).
- Store those embeddings in a **Qdrant vector database**.
- Search using natural language queries (e.g., â€œbreach of contract in retailâ€) and instantly retrieve semantically similar cases.

This is a **pure retrieval AI system** â€” optimized for accuracy, speed, and simplicity.

---

## ğŸ§© Core Capabilities

### ğŸ” 1. Smart Legal Search (Semantic Retrieval)

Instead of searching for keywords, this app finds documents based on **meaning**.  
It uses embeddings generated by `sentence-transformers` (`all-MiniLM-L6-v2` model) to understand the semantic relationship between sentences.

Example:

> Query: â€œbreach of contract in retailâ€  
> Matches: â€œSupplier failed to deliver goods on time.â€  
> (Even though the word â€˜breachâ€™ is not explicitly present.)

### ğŸ“„ 2. File Upload & Ingestion

- Upload `.pdf` or `.txt` legal documents via the frontend UI.
- Extracts and normalizes text (using `pdfplumber` for PDFs).
- Splits text into overlapping chunks for better context recall.
- Embeds each chunk and stores it in Qdrant with metadata.

### âš¡ 3. Vector Search Engine (Qdrant)

- Qdrant stores each text chunk as a **vector** along with metadata.
- When a query is made, Qdrant performs **cosine similarity** search to find the most semantically relevant text segments.

### ğŸ§  4. Fully Local AI (No API Keys Needed)

- Uses a **local embedding model** (no OpenAI or external API).
- Runs completely offline using Docker Compose.
- Great for privacy and local testing of AI-powered retrieval.

---

## ğŸ—ï¸ Architecture

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     Next.js UI     â”‚
                â”‚ (Upload + Search)  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ HTTP (Axios)
                          â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     FastAPI API    â”‚
                â”‚  /ingest & /search â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Sentence Transformerâ”‚
                â”‚  (Embeddings Model) â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     Qdrant DB      â”‚
                â”‚ Vector + Metadata  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Tech Stack

| Layer               | Technology                                     | Purpose                                         |
| ------------------- | ---------------------------------------------- | ----------------------------------------------- |
| ğŸ§± Backend          | **FastAPI**                                    | REST API for ingestion and search               |
| ğŸ§  AI Model         | **Sentence Transformers (`all-MiniLM-L6-v2`)** | Embedding generation for semantic understanding |
| ğŸ§® Vector DB        | **Qdrant**                                     | Vector similarity search & metadata storage     |
| ğŸ’» Frontend         | **Next.js + React + Axios**                    | UI for file upload & semantic search            |
| ğŸ§° Containerization | **Docker & Docker Compose**                    | One-command deployment for full stack           |
| ğŸ§¾ Text Extraction  | **pdfplumber**                                 | Converts PDF pages into text                    |

---

## ğŸ§  AI Working Principle

1. **Text Embedding** â€” Each paragraph/chunk is converted into a numeric vector that represents meaning.
2. **Vector Storage** â€” These embeddings are stored in Qdrant with metadata like filename and position.
3. **Query Embedding** â€” A search query is also converted into a vector.
4. **Similarity Search** â€” Qdrant retrieves top-N vectors most similar to the query (cosine distance).
5. **Result Return** â€” The backend returns the text snippets with highest semantic relevance.

---

## ğŸ§° How to Run Locally

### 1ï¸âƒ£ Prerequisites

- Docker & Docker Compose installed

### 2ï¸âƒ£ Clone and Run

```bash
git clone <repo-url>
cd evatt-mini-casebase
docker-compose up --build
```

Access:

- Frontend â†’ http://localhost:3000
- Backend â†’ http://localhost:8000
- Qdrant â†’ http://localhost:6333

### 3ï¸âƒ£ Upload & Search

1. Open the frontend (localhost:3000).
2. Upload a `.txt` or `.pdf` file.
3. Wait for â€œIngested X chunksâ€ message.
4. Type a natural language query â€” e.g. _â€œcontract breach in supplier caseâ€_.
5. View ranked semantic results.

---

## ğŸ§© Example Output

**Upload Result:**

```json
{ "ingested_chunks": 3 }
```

**Search Query:**

```json
{
  "query": "breach of contract in retail",
  "results": [
    {
      "score": 0.892,
      "text": "This case concerns a breach of contract where Supplier Ltd failed...",
      "source": "case_01.txt"
    }
  ]
}
```

---

## ğŸ’¡ Key Strengths

âœ… Pure AI-powered retrieval (semantic understanding)  
âœ… Fully local â€” no external API or cloud dependency  
âœ… Handles PDF & text ingestion automatically  
âœ… Fast, lightweight, and production-ready architecture  
âœ… Perfect foundation for building a legal RAG (Retrieval-Augmented Generation) system

---

## ğŸ‘¨â€ğŸ’» Author Notes

This project showcases a **complete working AI retrieval pipeline** â€” combining NLP embeddings, vector search, and web integration.  
It demonstrates how natural language search can be applied in the legal domain to retrieve contextually similar cases with high accuracy.
